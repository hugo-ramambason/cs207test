{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone2",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugo-ramambason/cs207test/blob/master/Milestone2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-5ZlL0fO_Nme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Milestone 2\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XnX1dhtN_TUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Differentiation is ubiquitous in almost all aspects of computer science, mathematics, and physics. It is used for numeric root-finding as in Newton's Method, and used for optimization with different forms of gradient descent.\n",
        "However, calculating analytic derivatives is difficult and can lead to exponentially growing abstract syntax trees, which makes finding the derivative infeasible in many cases.\n",
        "Similarly, calculating the derivative numerically using the limit definition runs into numeric instabilities due to limited machine precision.\n",
        "Automatic differentiation addresses both of these issues - it uses the chain rule and the fact that computers calculate any function as a sequence of elementary operations to find the derivative."
      ]
    },
    {
      "metadata": {
        "id": "2L2ci5Tw_ZJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installation and Usage\n",
        "\n",
        "\n",
        "### Installing from Source\n",
        "\n",
        "If you want the latest nightly version of AutoDiffX, clone from our github\n",
        "repository and install the latest version directly.\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/CS207-Project-Team-1/cs207-FinalProject autodiffx\n",
        "cd autodiffx\n",
        "pip install -r requirements.txt\n",
        "python3 setup.py install\n",
        "```\n",
        "\n",
        "If you are working on a python virtual environment or Mac OSX or your user's\n",
        "python distribution, this should work. If editing the system python, you may\n",
        "need to run the last command with root permissions by adding `sudo`.\n",
        "\n",
        "### Installing from pip\n",
        "\n",
        "For the stable version, you can install our package from PyPI.\n",
        "\n",
        "```bash\n",
        "pip install autodiffx\n",
        "```\n",
        "\n",
        "## Testing\n",
        "\n",
        "All of the tests are run using pytest. To run pytest, you want to be in the\n",
        "root directory of the repository. To ensure that `pytest` gets the imports\n",
        "correct, you want to run it such that it adds the current path to `PYTHONPATH`.\n",
        "The easiest way to do so is:\n",
        "\n",
        "```bash\n",
        "python -m pytest\n",
        "```\n",
        "\n",
        "This should run all of the tests for the package.\n",
        "\n",
        "Currently, our only module that we actually use lives in the `ad/` folder. The tests can be found in the different test files in `ad/tests`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QSxx1_h9_UTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "\n",
        "Automatic differentiation relies heavily on the principles of chain rule differentiation. A graph of elementary functions is built to calculate the values of more complex functions. Using the chain rule on the graph of elementary functions, the value of the derivative at each node can also be calculated. This gives us the ability to calculate the values of functions and their derivatives, no matter how complex, to near machine precision (a significant advantage compared to alternatives such as finite differences). \n",
        "\n",
        "The chain rule tells us that:\n",
        "\\begin{align}\n",
        "\\frac{d}{dx}(f(g(x))) &= f'(g(x))g'(x)\\\\\n",
        "\\end{align}\n",
        "\n",
        "Since each step in our graph is just a combination of linear operations, we can find the derivative at a node by considering the value and derivative of the expressions at the previous node. By starting with an initial 'seed' vector for the derivative (often set to 1), we can find the derivative in any desired search direction. \n",
        "\n",
        "Below is an example of constructing a graph to find the exact values of a function and its derivative. The function we used was:\n",
        "\n",
        "$$f\\left(x, y, z\\right) = \\dfrac{1}{xyz} + \\sin\\left(\\dfrac{1}{x} + \\dfrac{1}{y} + \\dfrac{1}{z}\\right)$$\n",
        "\n",
        "We worked through this, starting with trace elements $x_1$ for $x$,  $x_2$ for $y$ and  $x_3$ for $z$. We wanted to solve this function at $(x, y, z) = (1, 2, 3)$.\n",
        "\n",
        "| Trace | Elementary Function | Current Value | Elementary Function Derivative | $\\nabla_{x}$ Value  | $\\nabla_{y}$ Value  | $\\nabla_{z}$ Value  |\n",
        "| :---: | :-----------------: | :-----------: | :----------------------------: | :-----------------: | :-----------------: | :-----------------: |\n",
        "| $x_{1}$ | $x$ | 1 | $\\dot{x}$ | 1 | 0 | 0 | \n",
        "| $x_{2}$ | $y$ | 2 | $\\dot{y}$ | 0 | 1 | 0 | \n",
        "| $x_{3}$ | $z$ | 3 | $\\dot{z}$ | 0 | 0 | 1 | \n",
        "| $x_{4}$ | $1/x_{1}$ | 1 | $-\\dot{x}_{1}/x_{1}^{2}$ | $-1$ | $0$ | $0$ | \n",
        "| $x_{5}$ | $1/x_{2}$ | 1/2 | $-\\dot{x}_{2}/x_{2}^{2}$ | $0$ | $-1/4$ | $0$ | \n",
        "| $x_{6}$ | $1/x_{3}$ | 1/3 |  $-\\dot{x}_{3}/x_{3}^{2}$ | $0$ | $0$ | $-1/9$ | \n",
        "| $x_{7}$ | $x_{4} + x_{5} + x_{6}$ | 11/6 |$\\dot{x}_{4} + \\dot{x}_{5} + \\dot{x}_{6}$ | -1 | -0.25 | -0.11 |\n",
        "| $x_{8}$ | $sin(x_{7})$ | 0.966 |$\\dot{x}_{7}cos(x_{7})$ | 0.260 | 0.065 | 0.029 | \n",
        "| $x_{9}$ | $x_{4}x_{5}x_{6}$| 1/6 |$\\dot{x}_{4}x_{5}x_{6} + \\dot{x}_{5}x_{4}x_{6} + \\dot{x}_{6}x_{4}x_{5} $ |-0.167 | -0.083  | -0.056 | \n",
        "| $x_{10}$ | $x_{8} + x_{9}$ | 1.132 |$\\dot{x}_{8} + \\dot{x}_{9}$ | 0.093| -0.018  | -0.027 | \n",
        "\n",
        "This isn't a very complicated function, but it shows how we can use the most basic of functions to create a graph allowing us to find exact values and gradients.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "z13vUmhoQFdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple Usage\n",
        "\n",
        "Right now, our package only supports scalar function of a scalar. Suppose that we wanted to find the derivative of a pretty complicated function\n",
        "\n",
        "$$f(x) = x \\exp(\\cos(x) + x^2)$$\n",
        "\n",
        "First, we have to allocate a Variable for our input variable $x$. We can do that, and give it a string identifier `\"x\"` for convenience later. \n",
        "\n",
        "```python\n",
        "import ad\n",
        "x = ad.Variable('x')\n",
        "```\n",
        "Now, we have to define our function. Our module `ad` has a lot of built in functions, and all of the regular operators `+`, `-`, `*`, `/`, `**` should also work. We can make our function $f(x)$ by just writing it out in code.\n",
        "\n",
        "```python\n",
        "f = x * ad.Exp(ad.Cos(x) + x ** 2)\n",
        "```\n",
        "\n",
        "Now, we've defined our function in terms of our input variable $x$. Now, in order to evaluate our function or evaluate the derivative at a specific point we actually have to provide a value for the input. Since we later plan on handling multiple variable inputs, we pass the input in as a dictionary. To evaluate the function, we use the function ```eval```. For the derivative at a point, we use ```d```. Suppose that we wanted to evaluate the function $f$ and its derivative at $x = 0$ and $x = 1$. We can just run:\n",
        "\n",
        "```python\n",
        ">>> f.eval({x: 0})\n",
        "\n",
        ">>> f.d({x: 0})\n",
        "\n",
        ">>> f.eval({x: 1})\n",
        "\n",
        ">>> f.d({x: 1})\n",
        "```\n",
        "\n",
        "A more complicated use-case (Newton's Method) can be found in a Jupyter notebook at the top level directory. "
      ]
    },
    {
      "metadata": {
        "id": "1cfu_jYk_iK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Software Organization"
      ]
    },
    {
      "metadata": {
        "id": "vF3Ni2RGPJTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Directory structure\n",
        "\n",
        "```bash\n",
        "cs207project\n",
        "├── LICENSE\n",
        "├── README\n",
        "├── docs\n",
        "│   ├── Milestone1.ipynb\n",
        "│   ├── Milestone2.ipynb\n",
        "│   └── SETUP.md\n",
        "├── ad\n",
        "│   ├── __init__.py\n",
        "│   ├── ad.py\n",
        "│   ├── simple_ops.py\n",
        "│   ├── activation_ops.py.../\n",
        "│   ├── Newton_Method_Demonstration.ipynb\n",
        "│   └── tests\n",
        "│       ├── test_complex_ops.py\n",
        "│       ├── test_expression.py\n",
        "│       ├── test_simple_ops.py\n",
        "│       └── test_vector.py\n",
        "├── requirements.txt\n",
        "└── setup.py\n",
        "```\n",
        "\n",
        "## Modules\n",
        "\n",
        "`ad`: Implementation of core structures used in our graph-based automatic differentiation library. +, -, *, /, and exponentiation is also implemented here to support simple operator overloading.\n",
        "\n",
        "`simple_ops`: Unary operations including Sin(x), Cos(x), Tan(x), Sinh(x), Cosh(x), Tanh(x), Exp(x), Log(x).\n",
        "\n",
        "## Test\n",
        "\n",
        "See Testing.\n",
        "\n",
        "## Installment\n",
        "\n",
        "See Installation and Usage\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "iUlwF_YJ_mBU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation Details\n",
        "\n",
        "We implemented our automatic differentiation using a graph based structure. First, the user will build up their function in terms of elementary operations. Then, the user will be able to feed a value for their input variables, and the package will calculate the derivatives at each step."
      ]
    },
    {
      "metadata": {
        "id": "dcrJbb9E_4ZC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Current Implementation"
      ]
    },
    {
      "metadata": {
        "id": "tvtimCjqAAdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our core data structure is the computational graph. Every node in the computational graph would be an \"Expression\", which is our core class. \n",
        "\n",
        "Based on \"Expression\", we have \"Variable(Expression)\", \"Constant(Expression)\", \"Unop(Expression)\" and \"Biop(Expression)\". \"Unop\" is for unary operations such as log and power. \"Biop\" is for binary operations such as addition. For \"Expression\" and its subclasses, there are two important attributes: \"grad\", a boolean variable indicating whether we want to calculate the derivative or not; children, a list of nodes pointing to current one, the number of children is one for \"Unop\" and the number of chilren for \"Biop\" is two.\n",
        "\n",
        "The elementary functions we support are:\n",
        "\n",
        "Unary operations: \n",
        "\n",
        "* Power(x, n)\n",
        "* Sin(x)\n",
        "* Cos(x)\n",
        "* Tan(x)\n",
        "* Sinh(x)\n",
        "* Cosh(x)\n",
        "* Tanh(x)\n",
        "* Exp(x)\n",
        "* Log(x).\n",
        "\n",
        "Binary operations: \n",
        "\n",
        "* Addition (+)\n",
        "* Substraction (-)\n",
        "* Multiplication (*)\n",
        "* Division (/)\n",
        "\n",
        "We will mainly be using `numpy` as an external dependency for mathematical and vector operations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yPdt0eOf_7xP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Future Implementation Plans"
      ]
    },
    {
      "metadata": {
        "id": "V6K5gmNpFFhL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Multivariate Inputs\n",
        "\n",
        "We want to also support getting the Jacobian when we have more than one input for a scalar function. We want to be able to support functions of the form\n",
        "$$f: \\mathbb{R}^m \\to \\mathbb{R}$$\n",
        "at the very least. Right now, our eval works for this case. However, our derivative function does not work, because we do not handle the case for partial derivatives yet. Our proposed implementation for multivariate inputs is by using a `dict` to hold the different partial derivatives. We can go through an example. Suppose that a user wanted the Jacobian of a function:\n",
        "\n",
        "$$f(x, y, z) = x  + y \\cos(yz)$$\n",
        "\n",
        "Then, we would be able to find the Jacobian in code using the following syntax.\n",
        "\n",
        "```python\n",
        ">>> x = ad.Variable('x')\n",
        ">>> y = ad.Variable('y')\n",
        ">>> z = ad.Variable('z')\n",
        "\n",
        ">>> f = x + y * ad.Cos(y * z)\n",
        "\n",
        ">>> f.eval({x:6, y:1, z:0})\n",
        "7\n",
        ">>> f.d({x:6, y:1, z:0})\n",
        "{x: 1, y: 1, z: 0}\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "3ATmUuOY_-c-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Multivariate Outputs\n",
        "\n",
        "Currently, our package only fully supports scalar functions of a single scalar. We are only able to support functions of the form:\n",
        "$$f: \\mathbb{R} \\to \\mathbb{R}$$\n",
        "\n",
        "However, the next step after supporting multivariate inputs is to also support multivariate outputs. We will create a wrapper class `ad.Vector` that essentially wraps multiple different `ad.Expression` instances together. This will allow us to combine multiple scalar functions into a multivariate function. For example, suppose that a user wanted to find the Jacobian of a function in the form:\n",
        "$$f: \\mathbb{R}^3 \\to \\mathbb{R}^3$$\n",
        "and suppose that the function was in the form:\n",
        "$$f(x, y, z) = \n",
        "\\begin{pmatrix}\n",
        "x + y + z \\\\\n",
        "\\cos(yz) \\\\\n",
        "\\exp(x - y - z)\n",
        "\\end{pmatrix}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "20yuQye7CLU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, we could represent this in code as follows.\n",
        "\n",
        "```python\n",
        ">>> x = ad.Variable('x')\n",
        ">>> y = ad.Variable('y')\n",
        ">>> z = ad.Variable('z')\n",
        "\n",
        ">>> f1 = x + y + z\n",
        ">>> f2 = ad.Cos(y * z)\n",
        ">>> f3 = ad.Exp(x - y - z)\n",
        "\n",
        ">>> f = ad.Vector(f1, f2, f3)\n",
        ">>> f.eval({x:0, y:0, z:0})\n",
        "[0, 1, 1]\n",
        "\n",
        ">>> f.d({x:0, y:0, z:0})\n",
        "{x: [1, 0, 1], y: [1, 0, -1], z: [1, 0, -1]}\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "4pZ4XasAJm8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Proposed Extension\n",
        "\n",
        "### Calculating the Hessian\n",
        "\n",
        "We will want to calculate the Hessian using Automatic Differentiation. This is useful for Control Theory applications, as well as many important algorithms used in robotics. Calculating the Hessian is useful for path planning, as well as for inverse kinematics. Since it is relatively difficult to get a closed form solution for the Hessian in complicated inverse kinematics problems, it is useful to be able to use Automatic Differentiation for the Hessian.\n",
        "\n",
        "### User Interface\n",
        "\n",
        "Our current implementation goal is to implement the Hessian for functions of the form\n",
        "$$f: \\mathbb{R}^m \\to \\mathbb{R}$$\n",
        "In this case, the Hessian should be a square matrix. Since the Hessian will be a square matrix with entries of the form\n",
        "$$\\frac{\\partial^2 f}{\\partial x_i \\partial x_j}$$\n",
        "for some $i, j$, it makes sense to return a dictionary of dictionaries for the Hessian. This will make it easy to index the Hessian as ```hessian[x][y]``` to get the second order derivative with respect to x and y. An example function and calculated Hessian will be look something similar to the follows.\n",
        "\n",
        "$$f: \\mathbb{R}^3 \\to \\mathbb{R}$$\n",
        "$$f(x, y, z) = xy + z$$\n",
        "\n",
        "Then, the code will use the function `hessian()` to calculate the Hessian at a certain point.\n",
        "\n",
        "```python\n",
        ">>> x = ad.Variable('x')\n",
        ">>> y = ad.Variable('y')\n",
        ">>> z = ad.Variable('z')\n",
        "\n",
        ">>> f = x * y + z\n",
        "\n",
        ">>> f.eval({x:1, y:1, z:1})\n",
        "2\n",
        "\n",
        ">>> f.hessian({x:1, y:1, z:1})\n",
        "{x: {x: 0, y: 1, z:} y: {x: 1, y: 0, z: 0} z: {x: 0, y: 0, z: 0}}\n",
        "```"
      ]
    }
  ]
}